{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMS\n",
    "max_iteration=100000\n",
    "lr=1.0e-14\n",
    "momentum=0.99\n",
    "weight_decay=0.0005\n",
    "interval_validate=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# to reproduce same results\n",
    "torch.manual_seed(1337)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        if(train):\n",
    "            rfile = root_dir+'pascal_data/pascal_data/train_id.txt'\n",
    "        else :\n",
    "            rfile = root_dir+'pascal_data/pascal_data/test_id.txt'\n",
    "        ldir = root_dir + 'VOCdevkit/VOC2010/JPEGImages/'\n",
    "        sdir = root_dir + 'pascal_data/pascal_data/SegmentationPart/'\n",
    "        self.transform = transform\n",
    "        self.img = []\n",
    "        self.seg = []\n",
    "        \n",
    "        with open(rfile,'r') as f:\n",
    "            for line in f:\n",
    "                    image = PIL.Image.open(ldir+line+'.jpg')\n",
    "                    self.img.append(image.convert('RGB'))\n",
    "                    segment = PIL.Image.open(sdir+line+'.png')\n",
    "                    self.seg.append(segment)\n",
    "#             PUT DATA IN CORRESPONDING VARS\n",
    "            \n",
    "            \n",
    "#             self.label.append(ord(file_path.split('/')[-2]) - ord('A')) #ord makes A,B,C.. to 0,1,2,.. respectively\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return len(self.img)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # idx - the index of the sample requested\n",
    "        #\n",
    "        # Open the image correspoding to idx, apply transforms on it and return a tuple (image, label)\n",
    "        # where label is an integer from 0-9 (since notMNIST has 10 classes)\n",
    "        if self.transform is None:\n",
    "            return (self.img[idx],self.seg[idx])\n",
    "        else:\n",
    "            img_transformed = self.transform(self.img[idx])\n",
    "#             RETURN VARS\n",
    "            return (img_transformed,self.seg[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((224,224)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='/extra_data/ayushya/', train=True, transform=composed_transform) # Supply proper root_dir\n",
    "test_dataset = CDATA(root_dir='/extra_data/ayushya/', train=False, transform=composed_transform) # Supply proper root_dir\n",
    "\n",
    "# Let's check the size of the datasets, if implemented correctly they should be 16854 and 1870 respectively\n",
    "print('Size of train dataset: %d' % len(train_dataset))\n",
    "print('Size of test dataset: %d' % len(test_dataset))\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "# Create loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "# DEFINE MODEL\n",
    "# model = torchfcn.models.FCN8s(n_class=21)\n",
    "\n",
    "resume = 0\n",
    "\n",
    "start_epoch = 0\n",
    "start_iteration = 0\n",
    "if cuda:\n",
    "    model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS\n",
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    # input: (n, c, h, w), target: (n, h, w)\n",
    "    n, c, h, w = input.size()\n",
    "    # log_p: (n, c, h, w)\n",
    "    log_p = F.log_softmax(input)\n",
    "    # log_p: (n*h*w, c)\n",
    "#     log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "#     log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
    "#     log_p = log_p.view(-1, c)\n",
    "    # target: (n*h*w,)\n",
    "#     mask = target >= 0\n",
    "#     target = target[mask]\n",
    "    loss = F.nll_loss(log_p, target, weight=weight, size_average=False)\n",
    "    if size_average:\n",
    "        loss /= mask.data.sum()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optim = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "def validate(iteration):\n",
    "        val_loss = 0\n",
    "        label_trues, label_preds = [], []\n",
    "        for batch_idx, (data, target) in tqdm.tqdm(\n",
    "                enumerate(test_loader), total=len(test_loader),\n",
    "                desc='Valid iteration=%d' % iteration, ncols=80,\n",
    "                leave=False):\n",
    "            \n",
    "#             INSERT TARGETS\n",
    "            if self.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            score = self.model(data)\n",
    "\n",
    "            loss = cross_entropy2d(score, target)\n",
    "            if np.isnan(float(loss.data[0])):\n",
    "                raise ValueError('loss is nan while validating')\n",
    "            \n",
    "            val_loss += float(loss.data[0]) / len(data)\n",
    "\n",
    "#             imgs = data.data.cpu()\n",
    "#             lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "#             lbl_true = target.data.cpu()\n",
    "                \n",
    "#         SAVE IMAGES        \n",
    "#         out = \"val_out/\"\n",
    "#         if not osp.exists(out):\n",
    "#             os.makedirs(out)\n",
    "#         out_file = osp.join(out, 'iter%.jpg' % iteration)\n",
    "#         scipy.misc.imsave(out_file, image)\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "def train_model():\n",
    "    max_epoch = int(math.ceil(1. * max_iter / len(train_loader)))\n",
    "    for epoch in tqdm.trange(0, max_epoch,\n",
    "                             desc='Train', ncols=80):\n",
    "#         INSERT TARGETS\n",
    "        for batch_idx, (data, target) in tqdm.tqdm( \n",
    "                enumerate(train_loader), total=len(train_loader),\n",
    "                desc='Train epoch=%d' % epoch, ncols=80, leave=False):\n",
    "            iteration = batch_idx + epoch * len(train_loader)\n",
    "            \n",
    "#             VALIDATE\n",
    "            if iteration % interval_validate == 0:\n",
    "                validate(iteration)\n",
    "\n",
    "#             MODIFY FOR TARGETS\n",
    "            if self.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optim.zero_grad()\n",
    "#             MODIFY FOR OUTPUTS\n",
    "            score = model(data)\n",
    "\n",
    "            loss = cross_entropy2d(score, target)\n",
    "            loss /= len(data)\n",
    "            if np.isnan(float(loss.data[0])):\n",
    "                raise ValueError('loss is nan while training')\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "#             METRICS\n",
    "#             metrics = []\n",
    "#             lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "#             lbl_true = target.data.cpu().numpy()\n",
    "#             for lt, lp in zip(lbl_true, lbl_pred):\n",
    "#                 acc, acc_cls, mean_iu, fwavacc = \\\n",
    "#                     torchfcn.utils.label_accuracy_score(\n",
    "#                         [lt], [lp], n_class=n_class)\n",
    "#                 metrics.append((acc, acc_cls, mean_iu, fwavacc))\n",
    "#             metrics = np.mean(metrics, axis=0)\n",
    "\n",
    "            if iteration >= max_iter:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
